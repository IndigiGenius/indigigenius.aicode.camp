{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week One Final Project: Movie Revenue Prediction and Exploration\n",
    "\n",
    "Where has week one gone! We have one more project for you to put a nice little bow on all of the hard work you've done so far. For this project, be persistent, be curious, and ask questions if you get stuck!\n",
    "\n",
    "## The Project\n",
    "\n",
    "You and your teammates will create one prediction model and *AT LEAST* three plots or charts. Everyone will present their model and their charts during the final session of the day.\n",
    "* Model predictions will be ranked according to their r-squared values and we will crown a winner!\n",
    "* Your plots should be driven by curiosity. Everyone will present at least one plot.\n",
    "\n",
    "## Helper Functions\n",
    "\n",
    "We've provided helper functions down below. If you need help remembering what they do, refer to the `airbnb_solution.ipynb` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use these packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Read in the data!\n",
    "spotify_data = pd.read_csv(\"spotify_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for splitting out text data that differs by column, but is representing a category\n",
    "# like genre, or artist, but not something track name\n",
    "\n",
    "#the code below splits out genres into their own categories\n",
    "genre_dummies = pd.get_dummies(spotify_data[\"track_genre\"])\n",
    "genre_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dummies_columns = genre_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dummies_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre_dummis is it's own dataframe, I want to contatenate it onto my spotify_data\n",
    "merged_data = pd.concat([spotify_data, genre_dummies], axis=1)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T USE THIS IF YOU DONT HAVE ANY DATA IN A DICTIONARY FORM\n",
    "\n",
    "# Helper Function: Feature Engineering\n",
    "# Use this to turn dictionary columns into useful features\n",
    "# We use the genre column as an example\n",
    "\n",
    "column = \"column\"  # FEEL FREE TO CHANGE THIS\n",
    "number_to_keep = 100\n",
    "\n",
    "def process_col_name(col_name):\n",
    "    col_name_list = ast.literal_eval(col_name)\n",
    "    if not isinstance(col_name_list, list):\n",
    "        return []\n",
    "    return [dic['name'] for dic in col_name_list if isinstance(dic, dict) and 'name' in dic]\n",
    "\n",
    "spotify_data[f'{column}_list'] = spotify_data[column].apply(process_col_name)\n",
    "\n",
    "# Compute the frequency of each col_name member\n",
    "freq = pd.Series([name for sublist in spotify_data[f'{column}_list'].tolist() for name in sublist]).value_counts()\n",
    "\n",
    "# Keep the top 100 most frequent col_name members\n",
    "top_col_name = freq[:number_to_keep].index.tolist()\n",
    "\n",
    "# Filter the lists in the column to only include top col_name members\n",
    "spotify_data[f'{column}_list'] = spotify_data[f'{column}_list'].apply(lambda x: [i for i in x if i in top_col_name])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "binary_matrix = pd.DataFrame(mlb.fit_transform(spotify_data[f'{column}_list']), columns=mlb.classes_)\n",
    "\n",
    "# Clean the column names: keep only alphanumeric characters and underscores\n",
    "binary_matrix.columns = binary_matrix.columns.str.replace('[^0-9a-zA-Z_]', '', regex=True)\n",
    "\n",
    "# Now, concatenate the binary matrix with the original DataFrame\n",
    "new_feature_names = binary_matrix.columns\n",
    "spotify_data = pd.concat([spotify_data, binary_matrix], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function: Two Bar Chart Plots\n",
    "groupby_variable = \"track_genre\"\n",
    "y_value = \"popularity\"\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 6))\n",
    "spotify_data.groupby(groupby_variable)[y_value].mean().plot(kind=\"bar\", ax=axs[0], title=f\"Average {y_value}\")\n",
    "spotify_data.groupby(groupby_variable)[y_value].count().plot(kind=\"bar\", ax=axs[1], title=f\"Count for each Bucket\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function: Scatter Plot\n",
    "\n",
    "x_value = \"speechiness\"\n",
    "y_value = \"popularity\"\n",
    "\n",
    "spotify_data.plot(x=x_value, y=y_value, kind=\"scatter\", alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function: Model Training\n",
    "features = [\"duration_ms\", \"danceability\", \"speechiness\"]\n",
    "\n",
    "target = \"popularity\"  # LEAVE THIS ALONE\n",
    "model_type = \"linear regression\"  # Options: \"random forest\" or \"linear regression\"\n",
    "features_to_show = 15\n",
    "\n",
    "\n",
    "if model_type == \"random forest\":\n",
    "    model = RandomForestRegressor()\n",
    "elif model_type == \"linear regression\":\n",
    "    model = LinearRegression()\n",
    "\n",
    "shuffled_data = spotify_data.sample(len(spotify_data))  # Shuffle our data\n",
    "train_data = shuffled_data[:int(len(shuffled_data)*0.8)]\n",
    "validation_data = shuffled_data[int(len(shuffled_data)*0.8):]\n",
    "\n",
    "model.fit(train_data[features], train_data[target])\n",
    "\n",
    "train_data[f\"predicted_{target}\"] = model.predict(train_data[features])\n",
    "validation_data[f\"predicted_{target}\"] = model.predict(validation_data[features])\n",
    "\n",
    "# How do we measure our success?\n",
    "print(\"Training Data Statistics\")\n",
    "print(\"mean_absolute_error: \", mean_absolute_error(train_data[target], train_data[f\"predicted_{target}\"]))\n",
    "print(\"mean_squared_error\", mean_squared_error(train_data[target], train_data[f\"predicted_{target}\"]))\n",
    "print(\"R**2\", r2_score(train_data[target], train_data[f\"predicted_{target}\"]))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Validation Data Statistics\")\n",
    "print(\"mean_absolute_error: \", mean_absolute_error(validation_data[target], validation_data[f\"predicted_{target}\"]))\n",
    "print(\"mean_squared_error\", mean_squared_error(validation_data[target], validation_data[f\"predicted_{target}\"]))\n",
    "print(\"R**2\", r2_score(validation_data[target], validation_data[f\"predicted_{target}\"]))\n",
    "\n",
    "if model_type == \"random forest\":\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-features_to_show:]  # sort top features\n",
    "\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Bar plot\n",
    "    ax.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title(f'Top {features_to_show} Feature Importances')\n",
    "    plt.show()\n",
    "\n",
    "if model_type == \"linear regression\":\n",
    "    coefficients = model.coef_\n",
    "    indices = np.argsort(np.abs(coefficients))[-features_to_show:]  # sort top features by magnitude\n",
    "\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Bar plot\n",
    "    ax.barh(range(len(indices)), coefficients[indices], color='g', align='center')\n",
    "    plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.title(f'Top {features_to_show} Feature Coefficients in Linear Regression')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
